name: Deploy AI Assistant

on:
  push:
    branches:
      - main

jobs:
  build-and-deploy:
    runs-on: self-hosted  # Use the self-hosted runner

    steps:
<<<<<<< HEAD

    # Checkout code
=======
    # Step 1: Checkout code
>>>>>>> parent of 3b076e3 (setup github runner for better performance)
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        fetch-depth: 0  # Ensure all files are checked out

    # Print working directory
    - name: Print working directory
      run: pwd

    - name: Create SSH Key
      run: |
        echo "${{ secrets.EC2_SSH_KEY }}" > learning.pem
        chmod 600 learning.pem

    - name: Add EC2 Host to Known Hosts
      run: |
        mkdir -p ~/.ssh                
        touch ~/.ssh/known_hosts
        ssh-keyscan -H 3.22.249.244 >> ~/.ssh/known_hosts

    - name: Copy Airflow files to EC2
      run: |
        scp -i learning.pem -r Airflow ubuntu@3.22.249.244:/home/ubuntu/

    # Deploy Airflow Services on EC2
    - name: Deploy Airflow Services
      run: |
        ssh -i learning.pem ubuntu@3.22.249.244 << EOF
          cd /home/ubuntu/Airflow
          docker-compose down --volumes --remove-orphans
          docker-compose build
          docker-compose up -d
        EOF

    # Set up Docker Buildx
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    # Log in to DockerHub
    - name: Log in to DockerHub
      run: |
        echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin

    # Build FastAPI Image (using direct Dockerfile reference)
    - name: Build FastAPI image using explicit Dockerfile
      run: |
        docker buildx build \
          --file /home/ubuntu/actions-runner/_work/LearningAssistant/LearningAssistant/fastapi/Dockerfile \
          /home/ubuntu/actions-runner/_work/LearningAssistant/LearningAssistant/fastapi

    # Build and push FastAPI image
    - name: Build and push FastAPI image
      run: |
        docker buildx build \
          --platform linux/amd64 \
          --push \
          --cache-from=type=registry,ref=${{ secrets.DOCKER_USERNAME }}/fastapi:latest \
          --cache-to=type=inline \
          --tag ${{ secrets.DOCKER_USERNAME }}/fastapi:latest \
          --tag ${{ secrets.DOCKER_USERNAME }}/fastapi:${{ github.sha }} \
          /home/ubuntu/actions-runner/_work/LearningAssistant/LearningAssistant/fastapi

    # Build and push Streamlit Image
    - name: Build and push Streamlit image
      run: |
        docker buildx build \
          --platform linux/amd64 \
          --push \
          --cache-from=type=registry,ref=${{ secrets.DOCKER_USERNAME }}/streamlit:latest \
          --cache-to=type=inline \
          --tag ${{ secrets.DOCKER_USERNAME }}/streamlit:latest \
          --tag ${{ secrets.DOCKER_USERNAME }}/streamlit:${{ github.sha }} \
          ./streamlit

    # Create .env file for secrets
    - name: Create .env file
      run: |
        echo "DEPLOYED_URL=${{ secrets.DEPLOYED_URL }}" > .env
        echo "SECRET_KEY=${{ secrets.SECRET_KEY }}" >> .env
        echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" >> .env
        echo "PINECONE_API_KEY=${{ secrets.PINECONE_API_KEY }}" >> .env
        echo "INDEX_NAME=${{ secrets.INDEX_NAME }}" >> .env
        echo "IMG_INDEX_NAME=${{ secrets.IMG_INDEX_NAME }}" >> .env
        echo "YOUTUBE_INDEX=${{ secrets.YOUTUBE_INDEX }}" >> .env
        echo "DIMENSION=${{ secrets.DIMENSION }}" >> .env
        echo "METRIC=${{ secrets.METRIC }}" >> .env
        echo "FASTAPI_URL=${{ secrets.FASTAPI_URL }}" >> .env
        echo "SNOWFLAKE_USER=${{ secrets.SNOWFLAKE_USER }}" >> .env
        echo "SNOWFLAKE_PASSWORD=${{ secrets.SNOWFLAKE_PASSWORD }}" >> .env
        echo "SNOWFLAKE_ACCOUNT=${{ secrets.SNOWFLAKE_ACCOUNT }}" >> .env
        echo "SNOWFLAKE_WAREHOUSE=${{ secrets.SNOWFLAKE_WAREHOUSE }}" >> .env
        echo "SNOWFLAKE_DATABASE=${{ secrets.SNOWFLAKE_DATABASE }}" >> .env
        echo "SNOWFLAKE_SCHEMA=${{ secrets.SNOWFLAKE_SCHEMA }}" >> .env
        echo "YOUTUBE_API_KEY=${{ secrets.YOUTUBE_API_KEY }}" >> .env
        echo "CLOUD_PROVIDER=${{ secrets.CLOUD_PROVIDER }}" >> .env 
        echo "REGION=${{ secrets.REGION }}" >> .env      
        echo "IMAGE_DIMENSIONS=${{ secrets.IMAGE_DIMENSIONS }}" >> .env  

    - name: Copy .env file to EC2
      run: |
        scp -i learning.pem .env ubuntu@3.22.249.244:/home/ubuntu/LearningAssistant/

    # Ensure Docker Network Exists
    - name: Ensure Docker Network Exists
      run: |
        docker network inspect learningassistant_app-network || docker network create learningassistant_app-network

    # Deploy with Docker Compose
    - name: Deploy with Docker Compose
      run: |
        docker-compose pull
        docker-compose up -d --remove-orphans

    - name: Cleanup SSH Key
      run: rm -f learning.pem

    # Verify Deployment
    - name: Check FastAPI service health
      run: |
        retries=10
        delay=10
        for i in $(seq 1 $retries); do
          echo "Checking FastAPI service health (attempt $i/$retries)..."
          curl -f http://3.22.249.244:8000/docs && break || sleep $delay
        done

    - name: Check Streamlit service health
      run: |
        retries=10
        delay=10
        for i in $(seq 1 $retries); do
          echo "Checking Streamlit service health (attempt $i/$retries)..."
          curl -f http://3.22.249.244:8501 && break || sleep $delay
        done
    
    # - name: Check Airflow service health
    #   run: |
    #     retries=10
    #     delay=10
    #     for i in $(seq 1 $retries); do
    #       echo "Checking Airflow service health (attempt $i/$retries)..."
    #       curl -f http://3.22.249.244:8080 && break || sleep $delay
    #     done
